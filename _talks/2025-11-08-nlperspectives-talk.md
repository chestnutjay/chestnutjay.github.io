---
title: "From Disagreement to Understanding: The Case for Ambiguity Detection in NLI"
event: "The fourth Workshop on Perspectivist Approaches to NLP (NLPerspectives) - EMNLP 2025"
location: "Suzhou, China"
date: 2025-11-08
type: "Presentation"
slides: "#"
video: https://underline.io/lecture/136995-from-disagreement-to-understanding-the-case-for-ambiguity-detection-in-nli
layout: talk
author_profile: true
---
This position paper argues that annotation disagreement in Natural Language Inference (NLI) is not mere noise but often reflects meaningful variation, especially when triggered by ambiguity in the premise or hypothesis. While underspecified guidelines and annotator behavior contribute to variation, content-based ambiguity provides a process-independent signal of divergent human perspectives. We call for a shift toward ambiguity-aware NLI that first identifies ambiguous input pairs, classifies their types, and only then proceeds to inference. To support this shift, we present a framework that incorporates ambiguity detection and classification prior to inference. We also introduce a unified taxonomy that synthesizes existing taxonomies, illustrates key subtypes with examples, and motivates targeted detection methods that better align models with human interpretation. Although current resources lack datasets explicitly annotated for ambiguity and subtypes, this gap presents an opportunity: by developing new annotated resources and exploring unsupervised approaches to ambiguity detection, we enable more robust, explainable, and human-aligned NLI systems.