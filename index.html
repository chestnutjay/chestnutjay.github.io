---
layout: home
author_profile: true
title: "About me"
---
<!-- <style>
body {
    font-size: 100%;
}
  
h1 {
font-size: 2.5em;
}

h2 {
font-size: 1.875em;
}

p {
font-size: 0.875em;
}
</style> -->

<!-- 
{% include figure image_path="assets/images/website_pic.jpg" alt="this is a placeholder image" %}

feature_row:
  - excerpt: "I am a PhD student at University of Florida under the supervision on Dr. Bonnie Dorr. My primary research focus is on exploring the usability of Abstract Meaning Representations (AMR). AMR is a representational formalism defined to represent the meaning of a text by presenting "Who did What to Whom". This formalism has been used in multiple complex Natural Language Processing tasks such as Summarization, Information Retrieval and Text generation. My effort is to study the possibility of using AMRs in sentiment analysis task in order to 
build a more explainable pipeline for the said task."

{% include feature_row type="center" %} -->
"I am a PhD student at the University of Florida, working under the guidance of Dr. Bonnie Dorr. My research is primarily centered on Natural Language Inference (NLI), a field that explores the semantic relationships between a given premise and hypothesis. Specifically, I focus on identifying ambiguous premise-hypothesis pairs that allow for multiple valid interpretations and integrating these complexities into general NLI systems. Additionally, my work involves recognizing instances that require additional commonsense knowledge for precise inference and developing methods to generate and incorporate this knowledge, thereby enhancing the performance of NLI pipelines."




<p>
<span class="label custom-label animated_label">Natural Language Inference</span>
<span class="label custom-label animated_label">Ambiguity in NLI</span>
<span class="label custom-label animated_label">Commonsense-Augmented Inference</span>
<span class="label custom-label animated_label">Abstract Meaning Representations</span>
</p>

<!-- <div class="news-section">
    <h1>News</h1>

    <div class="news-item">
      <span class="emoji">üìù</span>
      New paper on using Abstract Meaning Representations (AMR) for explainable fact verification, <a href="https://aclanthology.org/2024.fever-1.26.pdf" target="_blank">"AMREx: AMR for Explainable Fact Verification"</a> accepted by FEVER workshop at EMNLP 2024.
    </div>

    <div class="news-item">
        <span class="emoji">üìù</span>
        New paper on using comparative analysis of rule-based and DNN models for political bias detection, <a href="https://aclanthology.org/2024.sicon-1.7.pdf" target="_blank">"DAHRS: Divergence-Aware Hallucination-Remediated SRL Projection"</a> accepted by NLDB 2024.
      </div>

    <div class="news-item">
        <span class="emoji">üìù</span>
        New paper on multi-lingual semantic role labeling projection<a href="https://link.springer.com/chapter/10.1007/978-3-031-70239-6_29" target="_blank">"Balancing Transparency and Accuracy: A Comparative Analysis of Rule-Based and Deep Learning Models in Political Bias Classification"</a> accepted by SICon workshop at EMNLP 2024.
      </div>  

  </div> -->

  <!-- Publications Newsfeed Section -->
<section class="newsfeed-container">
    <div class="newsfeed-header">
        <h1><b>Recent Publications</b></h1>
    </div>

    <div class="newsfeed-content" id="newsfeed">
        <!-- Replace with your actual publications -->
         <div class="news-item">
            <div class="news-date">Jan 05, 2026</div>
            <span class="news-badge badge-preprint">Preprint</span>
            <div class="news-title">
                <a href="https://arxiv.org/abs/2507.15100" target="_blank">Filling the Gap: Is Commonsense Knowledge Generation useful for Natural Language Inference?</a>
            </div>
            <div class="news-venue">Preprint</div>
            <div class="news-description">
                This study examines whether Large Language Models (LLMs) can generate useful commonsense axioms for Natural Language Inference and shows that a hybrid approach, which selectively provides highly factual axioms based on judged helpfulness, yields consistent accuracy improvements across all tested configurations, demonstrating the effectiveness of selective knowledge access for NLI.
            <div class="news-links">
                <a href="https://arxiv.org/abs/2507.15100" class="news-link" target="_blank">üìÑ Arxiv</a>
                <!-- <a href="https://github.com/your-username/your-repo" class="news-link" target="_blank">üíª Code</a> -->
                <!-- <a href="#" class="news-link" target="_blank">üìä Data</a> -->
            </div>
        </div>
        <div class="news-item">
            <div class="news-date">Nov 08, 2025</div>
            <span class="news-badge badge-accepted">Accepted</span>
            <div class="news-title">
                <a href="https://aclanthology.org/2025.nlperspectives-1.4/" target="_blank">From Disagreement to Understanding: The Case for Ambiguity Detection in NLI</a>
            </div>
            <div class="news-venue">Accepted to NLPerspectives EMNLP 2025</div>
            <div class="news-description">
                This position paper argues that annotation disagreement in Natural Language Inference (NLI) is not mere noise but often reflects meaningful interpretive variation, especially when triggered by ambiguity in the premise or hypothesis. While underspecified guidelines and annotator behavior can contribute to variation, content-based ambiguity offers a process-independent signal of divergent human perspectives. We call for a shift toward ambiguity-aware NLI by systematically identifying ambiguous input pairs and classifying ambiguity types.             </div>
            <div class="news-links">
                <a href="https://aclanthology.org/2025.nlperspectives-1.4/" class="news-link" target="_blank">üìÑ Paper</a>
                <!-- <a href="https://github.com/your-username/your-repo" class="news-link" target="_blank">üíª Code</a> -->
                <!-- <a href="#" class="news-link" target="_blank">üìä Data</a> -->
            </div>
        </div>


        <div class="news-item">
            <div class="news-date">November 02, 2024</div>
            <span class="news-badge badge-accepted">Accepted</span>
            <div class="news-title">
                <a href="https://aclanthology.org/2024.fever-1.26/" target="_blank">AMREx: Abstract Meaning Representation for Fact Verification</a>
            </div>
            <div class="news-venue">Accepted to FEVER EMNLP 2024</div>
            <div class="news-description">
                We implement AMREx, an Abstract Meaning Representation (AMR)-based veracity prediction and explanation system for fact verification using a combination of Smatch, an AMR evaluation metric to measure meaning containment and textual similarity. AMREx surpasses the AVeriTec baseline accuracy showing the effectiveness of our approach for real-world claim verification.
            </div>
            <div class="news-links">
                <a href="https://aclanthology.org/2024.fever-1.26/" class="news-link" target="_blank">üìÑ Paper</a>
                <!-- <a href="https://github.com/your-username/your-repo" class="news-link" target="_blank">üíª Code</a> -->
                <!-- <a href="#" class="news-link" target="_blank">üìä Data</a> -->
            </div>
        </div>

        <div class="news-item">
            <div class="news-date">November 02, 2024</div>
            <span class="news-badge badge-accepted">Accepted</span>
            <div class="news-title">
                <a href="https://aclanthology.org/2024.sicon-1.7/" target="_blank">Balancing Transparency and Accuracy: A Comparative Analysis of Rule-Based and Deep Learning Models in Political Bias Classification</a>
            </div>
            <div class="news-venue">Accepted to SciCon EMNLP 2024</div>
            <div class="news-description">
                We perform a comparative analysis of rule-based and DNN models for political bias detection by contrasting the opaque architecture of a deep learning model with the transparency of a linguistically informed rule-based model, and show that the rule-based model performs consistently across different data conditions and offers greater transparency, whereas the deep learning model is dependent on the training set and struggles with unseen data. 
            </div>
            <div class="news-links">
                <a href="https://aclanthology.org/2024.sicon-1.7/" class="news-link" target="_blank">üìÑ Paper</a>
                <!-- <a href="https://github.com/your-username/your-repo" class="news-link" target="_blank">üíª Code</a> -->
            </div>
        </div>

        <div class="news-item">
            <div class="news-date">July 12, 2024</div>
            <span class="news-badge badge-accepted">Accepted</span>
            <div class="news-title">
                <a href="https://link.springer.com/chapter/10.1007/978-3-031-70239-6_29" target="_blank">DAHRS: Divergence-Aware Hallucination-Remediated SRL Projection</a>
            </div>
            <div class="news-venue">Accepted to NLDB 2024</div>
            <div class="news-description">
                We implement Divergence-Aware Hallucination-Remediated SRL projection (DAHRS), leveraging linguistically-informed alignment remediation followed by greedy First-Come First-Assign (FCFA) SRL projection. DAHRS improves the accuracy of SRL projection without additional transformer-based machinery, beating XSRL in both human and automatic comparisons, and advancing beyond headwords to accommodate phrase-level SRL projection (e.g., EN-FR, EN-ES).
            </div>
            <div class="news-links">
                <a href="https://link.springer.com/chapter/10.1007/978-3-031-70239-6_29" class="news-link" target="_blank">üìÑ Paper</a>
                <!-- <a href="https://github.com/your-username/your-repo" class="news-link" target="_blank">üíª Code</a> -->
            </div>
        </div>
        
        <!-- Add more news items here using the template below -->
    </div>
</section>


  <style>
   /* Newsfeed Styles - Add to your existing CSS */
    .newsfeed-container {
        max-width: 800px;
        margin: 2rem auto;
        background: white;
        border-radius: 12px;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        overflow: hidden;
    }

    .newsfeed-header {
        background: white;
        color: #333;
        padding: 1.5rem 1.5rem 1rem 1.5rem;
        border-bottom: 1px solid #e2e8f0;
    }

    .newsfeed-header h2 {
        font-size: 1.2rem;
        font-weight: normal;
        margin-bottom: 0;
        color: #333;
    }

    .newsfeed-content {
        max-height: 500px;
        overflow-y: auto;
        padding: 0;
    }

    .newsfeed-content::-webkit-scrollbar {
        width: 8px;
    }

    .newsfeed-content::-webkit-scrollbar-track {
        background: #f1f5f9;
    }

    .newsfeed-content::-webkit-scrollbar-thumb {
        background: #cbd5e1;
        border-radius: 4px;
    }

    .newsfeed-content::-webkit-scrollbar-thumb:hover {
        background: #94a3b8;
    }

    .news-item {
        border-bottom: 1px solid #e2e8f0;
        border-left: 4px solid #8377D1;
        padding: 1.5rem;
        margin-left: 0;
        margin-bottom: 1rem;
        transition: all 0.2s ease;
    }

    .news-item:hover {
        background-color: #f8fafc;
    }

    .news-item:last-child {
        border-bottom: none;
        margin-bottom: 0;
    }

    .news-date {
        font-size: 0.8rem;
        color: #64748b;
        margin-bottom: 0.5rem;
        font-weight: 500;
    }

    .news-badge {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        border-radius: 12px;
        font-size: 0.75rem;
        font-weight: 600;
        margin-bottom: 0.75rem;
        text-transform: uppercase;
        letter-spacing: 0.05em;
    }

    .badge-preprint {
        background: #fef3c7;
        color: #92400e;
    }

    .badge-accepted {
        background: #d1fae5;
        color: #065f46;
    }

    .badge-published {
        background: #dbeafe;
        color: #1e40af;
    }

    .news-title {
        font-size: 1.1rem;
        font-weight: 600;
        color: #1e293b;
        margin-bottom: 0.5rem;
        line-height: 1.4;
    }

    .news-title a {
        color: inherit;
        text-decoration: none;
        transition: color 0.2s ease;
    }

    .news-title a:hover {
        color: #667eea;
    }

    .news-venue {
        font-size: 0.9rem;
        color: #475569;
        font-style: italic;
        margin-bottom: 0.75rem;
    }

    .news-description {
        font-size: 0.9rem;
        color: #64748b;
        line-height: 1.6;
        margin-bottom: 0.75rem;
    }

    .news-links {
        display: flex;
        gap: 0.75rem;
        flex-wrap: wrap;
    }

    .news-link {
        display: inline-flex;
        align-items: center;
        gap: 0.25rem;
        padding: 0.4rem 0.8rem;
        background: #f1f5f9;
        color: #475569;
        text-decoration: none;
        border-radius: 6px;
        font-size: 0.8rem;
        font-weight: 500;
        transition: all 0.2s ease;
    }

    .news-link:hover {
        background: #e2e8f0;
        color: #334155;
    }

    @media (max-width: 640px) {
        .news-links {
            flex-direction: column;
        }
        
        .news-link {
            justify-content: center;
        }
    }
.animated_label {
    border: none;
    color: #f0f0f0;
    margin-bottom: 5px;
    font-size: smaller;
}
.custom-label {
    height: 28px;
    color: #f0f0f0;
    /* background:  ; #b60e4e */
    background: #8377D1;
    border-radius: 5px;
    padding: 5px 15px;
    transition: all 0.3s ease;
    position: relative;
    display: inline-block;
    box-shadow: inset 2px 2px 2px 0px rgba(255,255,255,0.5), 7px 7px 20px 0px rgba(0,0,0,0.1), 4px 4px 5px 0px rgba(0,0,0,0.1);
    outline: none;
    font-size: smaller;
}


.animated_label::after {

    position: absolute;
    content: "";
    width: 0;
    height: 100%;
    top: 0;
    left: 0;
    direction: rtl;
    z-index: -1;
    border-radius: 5px;
    box-shadow: -7px -7px 20px 0px #fff9, -4px -4px 5px 0px #fff9, 7px 7px 20px 0px #0002, 4px 4px 5px 0px #0001;
    transition: all 0.3s ease;

}

  </style>


<!-- <style>
    /* .label {
  color: #f0f0f0 var(--label-text-color);
  background: #b60e4e var(--label-color);
  padding: 8px;
} */

.animated_label {
    border: none;
    color: #f0f0f0;
    margin-bottom: 5px;
    font-size: smaller;
}
.custom-label {
    height: 28px;
    color: #f0f0f0;
    /* background:  ; #b60e4e */
    background: #8377D1;
    border-radius: 5px;
    padding: 5px 15px;
    transition: all 0.3s ease;
    position: relative;
    display: inline-block;
    box-shadow: inset 2px 2px 2px 0px rgba(255,255,255,0.5), 7px 7px 20px 0px rgba(0,0,0,0.1), 4px 4px 5px 0px rgba(0,0,0,0.1);
    outline: none;
    font-size: smaller;
}



.animated_label::after {

    position: absolute;
    content: "";
    width: 0;
    height: 100%;
    top: 0;
    left: 0;
    direction: rtl;
    z-index: -1;
    border-radius: 5px;
    box-shadow: -7px -7px 20px 0px #fff9, -4px -4px 5px 0px #fff9, 7px 7px 20px 0px #0002, 4px 4px 5px 0px #0001;
    transition: all 0.3s ease;

}
/* .NLP {background-color: #04AA6D;} /* Green */
/* .XAI {background-color: #2196F3;} Blue */
/* .ML {background-color: #ff9800;} Orange */
/* .DS {background-color: #f44336;} Red */ 

.news-section {
      max-width: 800px;
      margin: auto;
    }
    .news-section h1 {
      text-align: left;
      color: #333;
    }
    .news-item {
      margin-bottom: 15px;
      padding: 10px;
      border-left: 4px solid #8377D1; /* Highlight bar */
      background-color: #f9f9f9;
    }
    .news-item .emoji {
      font-size: 1.5em;
      margin-right: 10px;
    }
    .news-item a {
      color: #007bff;
      text-decoration: none;
    }
    .news-item a:hover {
      text-decoration: underline;
    }
</style>
 -->
